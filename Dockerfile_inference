# Dockerfile_inference

# Using Python 3.10 base image
FROM python:3.10

# Setting the working directory inside the container
WORKDIR /app

# Copy the entire project directory into the container
COPY . .

# Installing necessary dependencies
RUN pip install --upgrade pip
RUN pip install -r ml_pipeline/requirements.txt

# Setting environment variables for paths used in the container
ENV MODEL_PATH=/app/ml_pipeline/models/xgboost_model.pkl

# Starting the FastAPI application for inference
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
