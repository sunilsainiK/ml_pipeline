version: '3.8'  # Specify the version of Docker Compose

services:
  training:
    image: ml__pipeline_training_image  # Useing the pre-built training image
    volumes:
      - ./data:/app/Data
    environment:
      - MODEL_PATH=/app/models/xgboost_model.pkl
      - DATA_PATH=/app/Data/datatraining.txt
    command: ["python", "-m", "monitoring"]  # Command to run training

  inference:
    image: ml__pipeline_inference_image  # Useing the pre-built inference image
    ports:
      - "8000:8000"  # Mapping the container port 8000 to host port 8000 for inference
    environment:
      - MODEL_PATH=/app/models/xgboost_model.pkl  # Same model path as training
    command: ["uvicorn", "api.prediction:router", "--host", "0.0.0.0", "--port", "8000"]  # Command to run inference
